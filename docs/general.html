<!DOCTYPE HTML>
<html>
	<head>
		<title>GACELA - A generative adversarial context encoder for long audio inpainting</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<link rel="stylesheet" href="assets/css/home.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">
		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<div class="inner">

							<!-- Logo -->
								<a href="index.html" class="logo">
									<span class="symbol"><img src="images/logo.svg" alt="" /></span><span class="title">Home</span>
								</a>

							<!-- Nav -->
								<nav>
									<ul>
										<li><a href="#menu">Menu</a></li>
									</ul>
								</nav>

						</div>
					</header>

				<!-- Menu -->
					<nav id="menu">
						<h2>Menu</h2>
						<ul>
							<li><a href="index.html">Home</a></li>
							<li><a href="general.html">The adversarial context encoder</a></li>
							<li><a href="complexity.html">Effect of the complexity</a></li>
							<li><a href="length.html">Effect of the gap length</a></li>
							<li><a href="latent-variable.html">Latent variable</a></li>
							<li><a href="comparison-SGA.html">Comparison SGA</a></li>
						</ul>
					</nav>

				<!-- Main -->
				<div id="main">
					<div class="inner">
						<header>
							<h1>GACELA - A generative adversarial context encoder for long audio inpainting</h1>

							<h1><img src="images/audio-inpainting.png" alt="General-1" width=70%></h1>

							<p>GACELA targets music inpainting in `long' gaps, i.e., in the range between hundreds of milliseconds and seconds. In this range, there are usually multiple plausible solutions for music inpainting and we consider the task as multi-modal. For example, on a gap where originally a single chord was played, there could be several other chords that fill in the gap while still sounding plausible. For each chord there are even several variations: different amount, intensities or onsets for each note. The multi-modality present at this range needs to be taken into account to model the task. Considering that a standard regression loss models a unique solution, it would lead to an average of the possible solutions and it is a bad fit for the task at this range. To solve this challenge, we model the task with a GAN, as it is able to model the distribution of possible gap replacements instead of producing a single candidate.
							</p>
							<p>
							An overview of our end-to-end audio generation is presented in the figure above.
							</p>

							<h1><img src="images/audio-inpainting-gan.png" alt="General-2" width=70%></h1>

						</header>



					</div>
				</div>

			<!-- Footer -->
				<footer id="footer">
					<div class="inner">
						<section>
							<h2>Resources</h2>
							<ul class="icons">
								<li><a href="mailto:andimarafioti@gmail.com" target="_blank" class="icon solid style2 fa-envelope"><span class="label">Email</span></a></li>
								<li><a href="https://github.com/andimarafioti/GANinpainting" target="_blank" class="icon brands style2 fa-github"><span class="label">GitHub</span></a></li>
							</ul>
						</section>
						<ul class="copyright">
							<li>&copy; All rights reserved</li>
						</ul>
					</div>
				</footer>

		</div>



		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>
	</body>
</html>
