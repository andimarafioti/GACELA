{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "import torch\n",
    "\n",
    "from data.audioLoader import AudioLoader\n",
    "from data.trainDataset import TrainDataset\n",
    "from ganSystem import GANSystem\n",
    "import logging\n",
    "\n",
    "# logging.getLogger().setLevel(logging.DEBUG)  # set root logger to debug\n",
    "\n",
    "\"\"\"Just so logging works...\"\"\"\n",
    "formatter = logging.Formatter('%(name)s:%(levelname)s:%(message)s')\n",
    "console_handler = logging.StreamHandler()\n",
    "console_handler.setLevel(logging.DEBUG)\n",
    "console_handler.setFormatter(formatter)\n",
    "logging.getLogger().addHandler(console_handler)\n",
    "\"\"\"Just so logging works...\"\"\"\n",
    "\n",
    "__author__ = 'Andres'\n",
    "\n",
    "signal_split = [480, 64, 480]\n",
    "md = 32\n",
    "\n",
    "params_stft_discriminator = dict()\n",
    "params_stft_discriminator['stride'] = [2, 2, 2, 2, 2]\n",
    "params_stft_discriminator['nfilter'] = [md, 2 * md, 4 * md, 8 * md, 16 * md]\n",
    "params_stft_discriminator['shape'] = [[5, 5], [5, 5], [5, 5], [5, 5], [5, 5]]\n",
    "params_stft_discriminator['data_size'] = 2\n",
    "\n",
    "params_mel_discriminator = dict()\n",
    "params_mel_discriminator['stride'] = [2, 2, 2, 2, 2]\n",
    "params_mel_discriminator['nfilter'] = [md//4, 2 * md//4, 4 * md//4, 8 * md//4, 16 * md//4]\n",
    "params_mel_discriminator['shape'] = [[5, 5], [5, 5], [5, 5], [5, 5], [5, 5]]\n",
    "params_mel_discriminator['data_size'] = 2\n",
    "\n",
    "params_generator = dict()\n",
    "params_generator['stride'] = [2, 2, 2, 2, 2]\n",
    "params_generator['nfilter'] = [8 * md, 4 * md, 2 * md, md, 1]\n",
    "params_generator['shape'] = [[4, 4], [4, 4], [8, 8], [8, 8], [8, 8]]\n",
    "params_generator['padding'] = [[1, 1], [1, 1], [3, 3], [3, 3], [3, 3]]\n",
    "params_generator['residual_blocks'] = 2\n",
    "\n",
    "params_generator['full'] = 256 * md\n",
    "params_generator['summary'] = True\n",
    "params_generator['data_size'] = 2\n",
    "params_generator['in_conv_shape'] = [16, 2]\n",
    "params_generator['borders'] = dict()\n",
    "params_generator['borders']['nfilter'] = [md, 2 * md, md, md / 2]\n",
    "params_generator['borders']['shape'] = [[5, 5], [5, 5], [5, 5], [5, 5]]\n",
    "params_generator['borders']['stride'] = [2, 2, 2, 2]\n",
    "params_generator['borders']['data_size'] = 2\n",
    "params_generator['borders']['border_scale'] = 1\n",
    "# This does not work because of flipping, border 2 need to be flipped tf.reverse(l, axis=[1]), ask Nathanael\n",
    "params_generator['borders']['width_full'] = None\n",
    "\n",
    "# Optimization parameters inspired from 'Self-Attention Generative Adversarial Networks'\n",
    "# - Spectral normalization GEN DISC\n",
    "# - Batch norm GEN\n",
    "# - TTUR ('GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium')\n",
    "# - ADAM  beta1=0 beta2=0.9, disc lr 0.0004, gen lr 0.0001\n",
    "# - Hinge loss\n",
    "# Parameters are similar to the ones in those papers...\n",
    "# - 'PROGRESSIVE GROWING OF GANS FOR IMPROVED QUALITY, STABILITY, AND VARIATION'\n",
    "# - 'LARGE SCALE GAN TRAINING FOR HIGH FIDELITY NATURAL IMAGE SYNTHESIS'\n",
    "# - 'CGANS WITH PROJECTION DISCRIMINATOR'\n",
    "\n",
    "params_optimization = dict()\n",
    "params_optimization['batch_size'] = 64\n",
    "params_stft_discriminator['batch_size'] = 64\n",
    "params_mel_discriminator['batch_size'] = 64\n",
    "\n",
    "params_optimization['n_critic'] = 1\n",
    "params_optimization['generator'] = dict()\n",
    "params_optimization['generator']['optimizer'] = 'adam'\n",
    "params_optimization['generator']['kwargs'] = [0.5, 0.9]\n",
    "params_optimization['generator']['learning_rate'] = 1e-4\n",
    "params_optimization['discriminator'] = dict()\n",
    "params_optimization['discriminator']['optimizer'] = 'adam'\n",
    "params_optimization['discriminator']['kwargs'] = [0.5, 0.9]\n",
    "params_optimization['discriminator']['learning_rate'] = 1e-4\n",
    "\n",
    "# all parameters\n",
    "params = dict()\n",
    "params['net'] = dict()  # All the parameters for the model\n",
    "params['net']['generator'] = params_generator\n",
    "params['net']['stft_discriminator'] = params_stft_discriminator\n",
    "params['net']['mel_discriminator'] = params_mel_discriminator\n",
    "params['net']['prior_distribution'] = 'gaussian'\n",
    "params['net']['shape'] = [1, 512, 1024]  # Shape of the image\n",
    "params['net']['inpainting'] = dict()\n",
    "params['net']['inpainting']['split'] = signal_split\n",
    "params['net']['gamma_gp'] = 10  # Gradient penalty\n",
    "# params['net']['fs'] = 16000//downscale\n",
    "params['net']['loss_type'] = 'wasserstein'\n",
    "\n",
    "params['optimization'] = params_optimization\n",
    "params['summary_every'] = 250  # Tensorboard summaries every ** iterations\n",
    "params['print_every'] = 50  # Console summaries every ** iterations\n",
    "params['save_every'] = 1000  # Save the model every ** iterations\n",
    "# params['summary_dir'] = os.path.join(global_path, name +'_summary/')\n",
    "# params['save_dir'] = os.path.join(global_path, name + '_checkpoints/')\n",
    "\n",
    "args = dict()\n",
    "args['generator'] = params_generator\n",
    "args['stft_discriminator_count'] = 2\n",
    "args['mel_discriminator_count'] = 3\n",
    "args['stft_discriminator'] = params_stft_discriminator\n",
    "args['mel_discriminator'] = params_mel_discriminator\n",
    "args['borderEncoder'] = params_generator['borders']\n",
    "args['stft_discriminator_in_shape'] = [1, 512, 64]\n",
    "args['mel_discriminator_in_shape'] = [1, 80, 64]\n",
    "args['mel_discriminator_start_powscale'] = 2\n",
    "args['generator_input'] = 1440\n",
    "args['optimizer'] = params_optimization\n",
    "args['split'] = signal_split\n",
    "args['log_interval'] = 100\n",
    "args['spectrogram_shape'] = params['net']['shape']\n",
    "args['gamma_gp'] = params['net']['gamma_gp']\n",
    "args['tensorboard_interval'] = 500\n",
    "args['save_path'] = '../saved_results/'\n",
    "args['experiment_name'] = 'real_data'\n",
    "args['save_interval'] = 10000\n",
    "\n",
    "args['fft_length'] = 1024\n",
    "args['fft_hop_size'] = 256\n",
    "args['sampling_rate'] = 22050\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "examples_per_file = 32\n",
    "audioLoader = AudioLoader(args['sampling_rate'], args['fft_length'], args['fft_hop_size'], 50)\n",
    "\n",
    "dataFolder = \"../../Datasets/maestro-v2.0.0/\"\n",
    "\n",
    "ganSystem = GANSystem(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_at_step = 400000\n",
    "start_at_epoch = 1\n",
    "\n",
    "ganSystem.loadModel(start_at_step, start_at_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from data.baseDataset import BaseDataset\n",
    "\n",
    "__author__ = 'Andres'\n",
    "\n",
    "\n",
    "class ValidDataset(BaseDataset):\n",
    "    def _sliceAudio(self, audio):\n",
    "        return audio\n",
    "\n",
    "    def _saveNewFile(self, name, audio, spectrogram):\n",
    "        self._loaded_files[name] = [0, spectrogram, audio]\n",
    "        self._index += 1\n",
    "\n",
    "    def __getitem__(self, unused_index):\n",
    "        filename = self._selectFile()\n",
    "        spectrogram, audio = self._loaded_files[filename][1], self._loaded_files[filename][2]\n",
    "\n",
    "        starts = np.random.randint(0, spectrogram.shape[1] - self._window_size, self._examples_per_file)\n",
    "\n",
    "        spectrograms = np.zeros([self._examples_per_file, self._audio_loader.windowLength()//2+1, self._window_size], dtype=np.float64)\n",
    "        audio_length = self._window_size*self._audio_loader.hopSize()\n",
    "        audios = np.zeros([self._examples_per_file, audio_length])\n",
    "\n",
    "        for index, start in enumerate(starts):\n",
    "            spectrograms[index] = spectrogram[:, start:start + self._window_size]\n",
    "            audio_start = np.min([start*self._audio_loader.hopSize(), audio.shape[0]-audio_length])\n",
    "            audios[index] = audio[audio_start:audio_start+audio_length]\n",
    "        self._usedFilename(filename)\n",
    "\n",
    "        return spectrograms[:, :-1], audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.audioLoader import AudioLoader\n",
    "# from data.validDataset import ValidDataset\n",
    "\n",
    "examples_per_file = 1\n",
    "loader_batch_size = 64\n",
    "\n",
    "dataFolder = \"../../../../Datasets/maestro-v2.0.0/\"\n",
    "\n",
    "validDataset = ValidDataset(dataFolder, window_size=1024, audio_loader=audioLoader, examples_per_file=examples_per_file, loaded_files_buffer=20, file_usages=1)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(validDataset,\n",
    "    batch_size=loader_batch_size//examples_per_file, shuffle=False,\n",
    "                                           num_workers=0, drop_last=True)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for data in valid_loader:\n",
    "    print('loaded')\n",
    "    spectrograms=data[0]\n",
    "    audios = data[1]\n",
    "    \n",
    "    audios = audios.view(loader_batch_size, -1)\n",
    "    \n",
    "    spectrograms = spectrograms.to(device).float()\n",
    "    spectrograms = spectrograms.view(loader_batch_size, *args['spectrogram_shape'])\n",
    "    spectrograms = torch.repeat_interleave(spectrograms, int(args['optimizer']['batch_size']/loader_batch_size), 0)\n",
    "    \n",
    "    left_borders = spectrograms[:, :, :, :args['split'][0]]\n",
    "    right_borders = spectrograms[:, :, :, args['split'][0] + args['split'][1]:]\n",
    "    print('generate')\n",
    "    generated_spectrograms = ganSystem.generateGap([left_borders, right_borders])\n",
    "\n",
    "    fake_spectrograms = torch.cat((left_borders, generated_spectrograms, right_borders), 3)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = ganSystem.border_encoders[0](ganSystem.time_average(ganSystem.mel_spectrogram(left_borders), 4))\n",
    "print(encoded.shape)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(encoded.detach().cpu().numpy().flatten(), 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(ganSystem.time_average(ganSystem.mel_spectrogram(left_borders), 4).detach().cpu().numpy().flatten(), 30)\n",
    "plt.imshow(ganSystem.time_average(ganSystem.mel_spectrogram(left_borders), 4).detach().cpu().numpy()[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "fig,a =  plt.subplots(2, 4, figsize=(6, 2), dpi=300, sharey=False, sharex=False)\n",
    "input_spectrogram = ganSystem.time_average(ganSystem.mel_spectrogram(left_borders), 4).detach().cpu().numpy()\n",
    "\n",
    "for inner in range(4):\n",
    "    im_bottom = a[0, inner].imshow(np.flip(input_spectrogram[inner+4, 0], 0),  cmap='inferno', vmax=0.41)\n",
    "    im_top = a[1, inner].imshow(np.flip(np.mean(encoded[inner+4].detach().cpu().numpy(), axis=0), 0),  cmap='inferno')\n",
    "\n",
    "    a[0, inner].tick_params(\n",
    "        axis='both',          # changes apply to the x-axis\n",
    "        which='both',      # both major and minor ticks are affected\n",
    "        bottom=False,      # ticks along the bottom edge are off,\n",
    "        left=False,\n",
    "        top=False,         # ticks along the top edge are off\n",
    "        labelleft=False,\n",
    "        labelbottom=False) # labels along the bottom edge are off\n",
    "    a[1, inner].tick_params(\n",
    "        axis='both',          # changes apply to the x-axis\n",
    "        which='both',      # both major and minor ticks are affected\n",
    "        bottom=False,      # ticks along the bottom edge are off\n",
    "        left=False,\n",
    "        top=False,         # ticks along the top edge are off\n",
    "        labelleft=False,\n",
    "        labelbottom=False) # labels along the bottom edge are off\n",
    "\n",
    "\n",
    "fig.tight_layout(pad=0.0, w_pad=1.0, h_pad=1.0)\n",
    "plt.savefig('left_border_mean_encoded_2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "\n",
    "input_spectrogram = ganSystem.time_average(ganSystem.mel_spectrogram(left_borders), 4).detach().cpu().numpy()\n",
    "\n",
    "fig = plt.figure(figsize=(12, 8), dpi=300, constrained_layout=True)\n",
    "\n",
    "gs = gridspec.GridSpec(4, 4, figure=fig, wspace=0.05, hspace=0.05)\n",
    "\n",
    "ax00 = fig.add_subplot(gs[:2, :2])\n",
    "ax00.imshow(np.flip(input_spectrogram[2, 0, :78], 0),  cmap='inferno') #Try to match the ratio of the encoded representation\n",
    "ax00.tick_params(\n",
    "        axis='both',          # changes apply to the x-axis\n",
    "        which='both',      # both major and minor ticks are affected\n",
    "        bottom=False,      # ticks along the bottom edge are off,\n",
    "        left=False,\n",
    "        top=False,         # ticks along the top edge are off\n",
    "        labelleft=False,\n",
    "        labelbottom=False) # labels along the bottom edge are off\n",
    "\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        if i<2 and j<2:\n",
    "            continue\n",
    "        \n",
    "        ax01 = fig.add_subplot(gs[i, j])\n",
    "        ax01.imshow(np.flip(encoded[2, 4*i+j].detach().cpu().numpy(), axis=0),  cmap='inferno')\n",
    "        ax01.tick_params(\n",
    "        axis='both',          # changes apply to the x-axis\n",
    "        which='both',      # both major and minor ticks are affected\n",
    "        bottom=False,      # ticks along the bottom edge are off,\n",
    "        left=False,\n",
    "        top=False,         # ticks along the top edge are off\n",
    "        labelleft=False,\n",
    "        labelbottom=False) # labels along the bottom edge are off\n",
    "\n",
    "                \n",
    "plt.savefig('left_border_encoded_v5.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
